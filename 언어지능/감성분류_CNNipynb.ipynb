{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeVumFErd-cI",
        "outputId": "6f09cc5e-edf0-4157-df17-5f9efdfbdc98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.10.0\n",
            "  Downloading torchtext-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 5.0 MB/s \n",
            "\u001b[?25hCollecting torch==1.9.0\n",
            "  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 831.4 MB 2.5 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchtext==0.10.0) (4.1.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (1.24.3)\n",
            "Installing collected packages: torch, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.13.1\n",
            "    Uninstalling torchtext-0.13.1:\n",
            "      Successfully uninstalled torchtext-0.13.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.9.0 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.9.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.9.0 torchtext-0.10.0\n"
          ]
        }
      ],
      "source": [
        "# torchtext.legacy를 사용할 수 있는 torchtext 버전 설치\n",
        "!pip install -U torchtext==0.10.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#colab 을 이용한 실행시\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCt984QzewsS",
        "outputId": "e1bd1cbf-c1d9-4497-9c5a-2652f1d0d7ac"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from torchtext.legacy import data\n",
        "import torchtext.datasets as datasets"
      ],
      "metadata": {
        "id": "kKnfZVZ3e2yt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN_Text(nn.Module):\n",
        "  def __init__(self,embed_num,class_num):\n",
        "    super(CNN_Text, self).__init__() # nn.Module의 변수 상속\n",
        "    # V: 사전의 크기\n",
        "    # D: embed_dim\n",
        "    # C: 분류하고자 하는 클래스의 개수\n",
        "    # Co : 각 커널(필터)의 갯수\n",
        "    V = embed_num\n",
        "    D = 100\n",
        "    C = class_num\n",
        "    Co = 100\n",
        "    Ks = [3,4,5]\n",
        "\n",
        "    self.embed = nn.Embedding(V,D)\n",
        "    self.convs1 = nn.ModuleList([nn.Conv2d(1,Co,(K,100)) for K in Ks])\n",
        "    self.dropout = nn.Dropout(0.2)\n",
        "    self.fc1 = nn.Linear(len(Ks)*Co,C)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.embed(x)\n",
        "    x = x.unsqueeze(1)\n",
        "    x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1]\n",
        "    x = [F.max_pool1d(i,i.size(2)).squeeze(2) for i in x]\n",
        "    x = torch.cat(x,1)\n",
        "    x = self.dropout(x)\n",
        "    logit = self.fc1(x)\n",
        "    return logit\n"
      ],
      "metadata": {
        "id": "cNEIb-3XfTQg"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class mydataset(data.Dataset):\n",
        "  @staticmethod\n",
        "  def sort_key(ex):\n",
        "    return len(ex.text)\n",
        "  def __init__(self, text_field, label_field, path=None, examples=None, **kwargs):\n",
        "    fields = [('text', text_field),('label',label_field)]\n",
        "    if examples is None:\n",
        "      path = self.dirname if path is None else path\n",
        "      examples = []\n",
        "      for i,line in enumerate(open(path,'r',encoding='utf-8')):\n",
        "        if i==0:\n",
        "          continue\n",
        "        line = line.strip().split('\\t')\n",
        "        txt = line[1].split(' ')\n",
        "\n",
        "        examples += [data.Example.fromlist([txt,line[2]],fields)]\n",
        "    super(mydataset, self).__init__(examples,fields,**kwargs)\n",
        "    "
      ],
      "metadata": {
        "id": "dsVZxn2AiQKa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_field = data.Field(batch_first = True,fix_length=20) # 전처리 관련 field 객체 생성 / fix_length : 하나의 문장 내 max 토큰 수\n",
        "label_field = data.Field(sequential=False,batch_first = True, unk_token = None) # 전처리 관련 field 객체 생성 / sequential : 시퀸스데이터 여부\n",
        "\n",
        "train_data = mydataset(text_field,label_field,path='/content/gdrive/My Drive/Colab Notebooks/aivle/data/nsm/small_ratings_train_tok.txt')\n",
        "test_data = mydataset(text_field,label_field,path='/content/gdrive/My Drive/Colab Notebooks/aivle/data/nsm/small_ratings_test_tok.txt')\n",
        "\n",
        "text_field.build_vocab(train_data)\n",
        "label_field.build_vocab(train_data)\n",
        "\n",
        "train_iter, test_iter = data.Iterator.splits(\n",
        "    (train_data,test_data),batch_sizes=(100,1)\n",
        ")\n",
        "\n",
        "print(len(text_field.vocab))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghD2cwA1jffI",
        "outputId": "758e4377-c159-478b-d726-e052a2dead31"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21893\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = CNN_Text(len(text_field.vocab),2)\n",
        "\n",
        "optimizer = torch.optim.Adam(cnn.parameters())\n",
        "cnn.train() #학습 모드"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpkxvJojkP4F",
        "outputId": "32c69d76-a352-45ed-9a5a-9a073b184eca"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN_Text(\n",
              "  (embed): Embedding(21893, 100)\n",
              "  (convs1): ModuleList(\n",
              "    (0): Conv2d(1, 100, kernel_size=(3, 100), stride=(1, 1))\n",
              "    (1): Conv2d(1, 100, kernel_size=(4, 100), stride=(1, 1))\n",
              "    (2): Conv2d(1, 100, kernel_size=(5, 100), stride=(1, 1))\n",
              "  )\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              "  (fc1): Linear(in_features=300, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(20):\n",
        "  totalloss = 0\n",
        "\n",
        "  for batch in train_iter:\n",
        "    optimizer.zero_grad() # 그래디언트 초기화\n",
        "\n",
        "    txt = batch.text\n",
        "    label = batch.label\n",
        "\n",
        "    pred = cnn(txt)\n",
        "\n",
        "    loss = F.cross_entropy(pred,label)\n",
        "    totalloss += loss.data\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "  print(epoch,'eopch')\n",
        "  print('loss : {:.3f}'.format(totalloss.numpy()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLhfji_kmTDS",
        "outputId": "ffbadf3d-0e77-45f2-b686-5b138491c8a8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 eopch\n",
            "loss : 65.933\n",
            "1 eopch\n",
            "loss : 50.602\n",
            "2 eopch\n",
            "loss : 36.296\n",
            "3 eopch\n",
            "loss : 24.258\n",
            "4 eopch\n",
            "loss : 15.471\n",
            "5 eopch\n",
            "loss : 11.195\n",
            "6 eopch\n",
            "loss : 7.853\n",
            "7 eopch\n",
            "loss : 5.805\n",
            "8 eopch\n",
            "loss : 4.459\n",
            "9 eopch\n",
            "loss : 3.695\n",
            "10 eopch\n",
            "loss : 3.448\n",
            "11 eopch\n",
            "loss : 2.799\n",
            "12 eopch\n",
            "loss : 2.296\n",
            "13 eopch\n",
            "loss : 2.046\n",
            "14 eopch\n",
            "loss : 2.079\n",
            "15 eopch\n",
            "loss : 1.708\n",
            "16 eopch\n",
            "loss : 1.634\n",
            "17 eopch\n",
            "loss : 1.301\n",
            "18 eopch\n",
            "loss : 1.364\n",
            "19 eopch\n",
            "loss : 1.643\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "cnn.eval() # 검증 모드\n",
        "correct = 0\n",
        "incorrect = 0\n",
        "y_test = []\n",
        "prediction = []\n",
        "\n",
        "for batch in test_iter:\n",
        "  txt = batch.text\n",
        "  label = batch.label\n",
        "  y_test.append(label.data[0])\n",
        "\n",
        "  pred = cnn(txt)\n",
        "  _,ans = torch.max(pred,dim=1)\n",
        "  prediction.append(ans.data[0])\n",
        "\n",
        "  if ans.data[0] == label.data[0]:\n",
        "    correct += 1\n",
        "  else :\n",
        "    incorrect += 1\n",
        "\n",
        "print('correct : ',correct) \n",
        "print('incorrect : ',incorrect) \n",
        "print(classification_report(torch.tensor(y_test),\n",
        "                            torch.tensor(prediction),\n",
        "                            digits=4,\n",
        "                            target_names=['negative','positive']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmlXYljqnRZA",
        "outputId": "4e260e6d-476d-402a-da39-c673e8983845"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "correct :  79\n",
            "incorrect :  21\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative     0.8222    0.7400    0.7789        50\n",
            "    positive     0.7636    0.8400    0.8000        50\n",
            "\n",
            "    accuracy                         0.7900       100\n",
            "   macro avg     0.7929    0.7900    0.7895       100\n",
            "weighted avg     0.7929    0.7900    0.7895       100\n",
            "\n",
            "CPU times: user 756 ms, sys: 94.2 ms, total: 850 ms\n",
            "Wall time: 1.55 s\n"
          ]
        }
      ]
    }
  ]
}