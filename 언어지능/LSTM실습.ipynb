{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8H35hNK0NvW",
        "outputId": "93423a55-886a-4098-c22f-616983e57a37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.10.0\n",
            "  Downloading torchtext-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 26.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (1.21.6)\n",
            "Collecting torch==1.9.0\n",
            "  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 831.4 MB 2.6 kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchtext==0.10.0) (4.1.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (3.0.4)\n",
            "Installing collected packages: torch, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.13.1\n",
            "    Uninstalling torchtext-0.13.1:\n",
            "      Successfully uninstalled torchtext-0.13.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.9.0 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.9.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.9.0 torchtext-0.10.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U torchtext==0.10.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5m0wLAao0XH5",
        "outputId": "e68aac97-df37-4c0c-d520-484ee1afe9e8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchtext.legacy import data\n",
        "import torchtext.datasets as datasets"
      ],
      "metadata": {
        "id": "yHGWBkwe0bPI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN_Text(nn.Module):\n",
        "  def __init__(self, embed_num, class_num):\n",
        "    super(RNN_Text, self).__init__()\n",
        "\n",
        "    #V : 단어 사전 크기\n",
        "    #C : 분류하고자 하는 클래스 개수\n",
        "    #H : 히든 사이즈\n",
        "    #D : 단어벡터 차원\n",
        "\n",
        "    V = embed_num\n",
        "    C = class_num\n",
        "    H = 256\n",
        "    D = 100\n",
        "    \n",
        "    self.embed = nn.Embedding(V,D)\n",
        "    self.rnn = nn.LSTM(D,H,bidirectional = True)\n",
        "    self.out = nn.Linear(H*2,C)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.embed(x)\n",
        "    x,_ = self.rnn(x,(self.h,self.c))\n",
        "    logit = self.out(x[-1])\n",
        "\n",
        "    return logit\n",
        "  \n",
        "  def inithidden(self,b):\n",
        "    self.h = torch.randn(2,b,256)\n",
        "    self.c = torch.randn(2,b,256)\n"
      ],
      "metadata": {
        "id": "YBnu0ii20qUv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class mydataset(data.Dataset):\n",
        "  @staticmethod\n",
        "  def sort_key(ex):\n",
        "    return len(ex.text)\n",
        "  def __init__(self, text_field, label_field, path=None, examples=None, **kwargs):\n",
        "    fields = [('text',text_field),('label',label_field)]\n",
        "    if examples is None:\n",
        "      path = self.dirname if path is None else path\n",
        "      examples = []\n",
        "      for i,line in enumerate(open(path,'r',encoding='utf-8')):\n",
        "        if i == 0:\n",
        "          continue\n",
        "        line = line.strip().split('\\t')\n",
        "        txt = line[1].split(' ')\n",
        "\n",
        "        examples += [data.Example.fromlist([txt,line[2]],fields)]\n",
        "    super(mydataset, self).__init__(examples, fields, **kwargs)"
      ],
      "metadata": {
        "id": "yBixakBb13JH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_field = data.Field(fix_length=30)\n",
        "label_field = data.Field(sequential=False, batch_first = True, unk_token = None)\n",
        "\n",
        "train_data = mydataset(text_field, label_field,path='/content/gdrive/My Drive/Colab Notebooks/aivle/data/nsm/small_ratings_train_tok.txt')\n",
        "test_data = mydataset(text_field, label_field,path='/content/gdrive/My Drive/Colab Notebooks/aivle/data/nsm/small_ratings_test_tok.txt')\n",
        "\n",
        "text_field.build_vocab(train_data)\n",
        "label_field.build_vocab(train_data)\n",
        "\n",
        "train_iter,test_iter = data.Iterator.splits(\n",
        "    (train_data,test_data),\n",
        "    batch_sizes=(100,1), repeat=False\n",
        ")\n"
      ],
      "metadata": {
        "id": "00YNUwue3qYL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn = RNN_Text(len(text_field.vocab),2)\n",
        "optimizer = torch.optim.Adam(rnn.parameters())\n",
        "rnn.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aC4SQarRZ0Hj",
        "outputId": "bc6c0c51-b54f-45d7-e917-7627216beabf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNN_Text(\n",
              "  (embed): Embedding(21893, 100)\n",
              "  (rnn): LSTM(100, 256, bidirectional=True)\n",
              "  (out): Linear(in_features=512, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for epoch in range(10):\n",
        "  totalloss = 0\n",
        "  for batch in train_iter:\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    txt=batch.text\n",
        "    label=batch.label\n",
        "\n",
        "    rnn.inithidden(txt.size(1))\n",
        "    pred = rnn(txt)\n",
        "\n",
        "    loss = F.cross_entropy(pred,label)\n",
        "    totalloss += loss.data\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  \n",
        "  print(epoch,'epoch')\n",
        "  print('loss : {:.3f}'.format(totalloss.numpy()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jz8TeyEkaD-O",
        "outputId": "72e93ebd-8651-4406-a4c3-1257d6a1e27d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 epoch\n",
            "loss : 69.768\n",
            "1 epoch\n",
            "loss : 69.269\n",
            "2 epoch\n",
            "loss : 65.924\n",
            "3 epoch\n",
            "loss : 53.854\n",
            "4 epoch\n",
            "loss : 41.693\n",
            "5 epoch\n",
            "loss : 31.672\n",
            "6 epoch\n",
            "loss : 24.346\n",
            "7 epoch\n",
            "loss : 17.879\n",
            "8 epoch\n",
            "loss : 13.014\n",
            "9 epoch\n",
            "loss : 9.869\n",
            "CPU times: user 6min 23s, sys: 13.5 s, total: 6min 37s\n",
            "Wall time: 6min 53s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "correct = 0\n",
        "incorrect = 0\n",
        "rnn.eval()\n",
        "y_test =[]\n",
        "prediction =[]\n",
        "\n",
        "for batch in test_iter:\n",
        "  txt = batch.text\n",
        "  label = batch.label\n",
        "  y_test.append(label.data[0])\n",
        "  \n",
        "  rnn.inithidden(txt.size(1))\n",
        "\n",
        "  pred = rnn(txt)\n",
        "\n",
        "  _, ans = torch.max(pred,dim=1)\n",
        "  prediction.append(ans.data[0])\n",
        "\n",
        "  if ans.data[0] == label.data[0]:\n",
        "    correct +=1\n",
        "  else:\n",
        "    incorrect +=1\n",
        "\n",
        "\n",
        "print('correct : ',correct)\n",
        "print('incorrect : ',incorrect)\n",
        "print(classification_report(\n",
        "    torch.tensor(y_test),\n",
        "    torch.tensor(prediction),\n",
        "    digits=4,\n",
        "    target_names=['negative','positive']\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMAFfU1McDYx",
        "outputId": "fd24fc8e-9599-40db-add6-beba7fca0865"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "correct :  84\n",
            "incorrect :  16\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative     0.7742    0.9600    0.8571        50\n",
            "    positive     0.9474    0.7200    0.8182        50\n",
            "\n",
            "    accuracy                         0.8400       100\n",
            "   macro avg     0.8608    0.8400    0.8377       100\n",
            "weighted avg     0.8608    0.8400    0.8377       100\n",
            "\n",
            "CPU times: user 781 ms, sys: 3.97 ms, total: 785 ms\n",
            "Wall time: 778 ms\n"
          ]
        }
      ]
    }
  ]
}